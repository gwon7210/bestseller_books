import requests
from bs4 import BeautifulSoup
import json
import os
import re
import sys


def scrape_yes24_bestsellers(category_name: str, category_number: str):
    books = []

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    url = (
        f"https://www.yes24.com/product/category/monthweekbestseller?"
        f"pageNumber=1&pageSize=24&categoryNumber={category_number}&"
        f"type=week&saleYear=2025"
    )

    try:
        print(f"ğŸ“¦ ì˜ˆìŠ¤24 '{category_name}' ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆ˜ì§‘ ì‹œì‘...")
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        book_items = soup.select("div.itemUnit")[:10]  # ìƒìœ„ 10ê°œë§Œ

        for item in book_items:
            try:
                img_tag = item.select_one("img.lazy")
                img = img_tag.get("data-original") or img_tag.get("src", "")
                if not img.startswith("http"):
                    img = "https:" + img

                title = img_tag.get("alt", "").strip()

                author_tag = item.select_one('a[href*="author"]')
                author = author_tag.text.strip() if author_tag else "ì •ë³´ ì—†ìŒ"

                publisher_tag = item.select_one('a[href*="company"]')
                publisher = publisher_tag.text.strip() if publisher_tag else "ì •ë³´ ì—†ìŒ"

                price_element = item.select_one("span.txt_num em.yes_m")
                price = (
                    price_element.text.strip().replace(",", "")
                    if price_element
                    else "0"
                )

                release_date_element = item.select_one("span.info_date")
                release_date = (
                    release_date_element.text.strip()
                    if release_date_element
                    else "ì •ë³´ ì—†ìŒ"
                )

                sales_element = item.select_one("span.saleNum")
                sales_index = (
                    sales_element.text.strip().replace("íŒë§¤ì§€ìˆ˜ ", "").replace(",", "")
                    if sales_element
                    else "0"
                )

                match = re.search(r"/goods/(\d+)", img)
                goods_id = match.group(1) if match else ""
                book_link = (
                    f"https://www.yes24.com/product/goods/{goods_id}"
                    if goods_id
                    else ""
                )

                book_info = {
                    "img": img,
                    "title": title,
                    "author": author,
                    "publisher": publisher,
                    "price": price,
                    "release_date": release_date,
                    "sales_index": sales_index,
                    "book_link": book_link,
                }

                books.append(book_info)
                print(f"ğŸ“š ìˆ˜ì§‘ ì™„ë£Œ: {title}")

            except Exception as e:
                print(f"âš ï¸ ê°œë³„ ë„ì„œ ì˜¤ë¥˜: {e}")
                continue

    except Exception as e:
        print(f"âŒ í˜ì´ì§€ ì˜¤ë¥˜: {e}")

    try:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë””ë ‰í„°ë¦¬ ì„¤ì •
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
        data_dir = os.path.join(project_root, f"{category_name}_data")
        os.makedirs(data_dir, exist_ok=True)
        filename = os.path.join(data_dir, f"yes24_{category_name}.json")

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(books, f, ensure_ascii=False, indent=2)

        print(f"âœ… ì´ {len(books)}ê¶Œ ìˆ˜ì§‘ ì™„ë£Œ â†’ {filename}")

    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("ì‚¬ìš©ë²•: python yes24_scraper.py [category_name] [category_number]")
        print("ì˜ˆì‹œ:  python yes24_scraper.py economics 001001025")
        sys.exit(1)

    category_name = sys.argv[1]
    category_number = sys.argv[2]

    scrape_yes24_bestsellers(category_name, category_number)
